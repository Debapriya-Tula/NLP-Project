# NLP-Project
## Task:
Recognition of Emotion from Speech directly.<br>

## Why the need from Speech to Emotion directly?
1) The main problem with traditional systems is that the errors occurred while transcribing audio is propagated and that affects the emotion recognition task.
2) We lose important acoustic features like pitch, loudness etc.
3) Confusing emotional contexts in some cases.
For example, the phrase, ‘What a man!’ can indicate surprise or even disgust.

## Motivation

Datasets used: 

1) [The Ryerson Audio-Visual Database of Emotional Speech and Song - RAVDESS](https://zenodo.org/record/1188976)

Only the audio tracks have been used.

Dataset description:

○ Gender balanced consisting of 24 professional
actors.<br>
○ 7 emotions in total: <b>calm, happy, sad,
angry,fearful, surprise, and disgust
expressions.</b><br>
○ Each expression is produced at two levels of
emotional intensity, with an additional neutral
expression.<br>
○ <b>1250</b> samples in total.

<br>


2) [Toronto Emotional Speech Set - TESS](https://www.kaggle.com/ejlok1/toronto-emotional-speech-set-tess)

Dataset description:

○ Voices of two actresses, aged 26 and 64.<br>
○ 7 emotions in total: <b>anger, disgust, fear, happiness, pleasant surprise, sadness, and neutral.</b><br>
○ Audiometric testing indicated that both actresses have thresholds within the normal range.<br>
○ <b>1370</b> samples in total.

